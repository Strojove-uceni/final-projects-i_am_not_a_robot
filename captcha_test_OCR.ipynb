{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Strojove-uceni/final-projects-i_am_not_a_robot/blob/main/captcha_test_OCR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXkze08zHJ-e"
      },
      "source": [
        "# Test of captcha code recognition using OCR model by keras.\n",
        "\n",
        "This code is inspired by \n",
        "* https://keras.io/examples/vision/captcha_ocr/\n",
        "* https://towardsdatascience.com/intuitively-understanding-connectionist-temporal-classification-3797e43a86c\n",
        "* https://www.youtube.com/watch?v=SHo3hbsJs_U&ab_channel=HenryAILabs "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrjRYa7cHhwQ"
      },
      "source": [
        "## Work space\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwcwCVAQHhLZ",
        "outputId": "b8ee65c2-1dae-45a0-dd7a-fbd7b23193d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting patool\n",
            "  Downloading patool-1.12-py2.py3-none-any.whl (77 kB)\n",
            "\u001b[?25l\r\u001b[K     |████▎                           | 10 kB 17.5 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 20 kB 21.6 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 30 kB 25.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 40 kB 16.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 51 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 61 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 71 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 77 kB 2.6 MB/s \n",
            "\u001b[?25hInstalling collected packages: patool\n",
            "Successfully installed patool-1.12\n",
            "Collecting pyunpack\n",
            "  Downloading pyunpack-0.2.2-py2.py3-none-any.whl (3.8 kB)\n",
            "Collecting entrypoint2\n",
            "  Downloading entrypoint2-0.2.4-py3-none-any.whl (6.2 kB)\n",
            "Collecting easyprocess\n",
            "  Downloading EasyProcess-0.3-py2.py3-none-any.whl (7.9 kB)\n",
            "Installing collected packages: entrypoint2, easyprocess, pyunpack\n",
            "Successfully installed easyprocess-0.3 entrypoint2-0.2.4 pyunpack-0.2.2\n"
          ]
        }
      ],
      "source": [
        "# install and load packages\n",
        "! pip install patool\n",
        "! pip install pyunpack\n",
        "\n",
        "import argparse\n",
        "import os\n",
        "import random\n",
        "import requests\n",
        "import zipfile\n",
        "import errno\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pyunpack import Archive\n",
        "import glob\n",
        "import string\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtX11AxGHFGk",
        "outputId": "71b37675-6da0-4d35-e796-6fba0cdb947c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "We are now using cpu. There are 0 available gpus.\n"
          ]
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "n_cudas = torch.cuda.device_count()\n",
        "\n",
        "print(f'We are now using {device}. There are {n_cudas} available gpus.')\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f'{torch.cuda.get_device_name(0)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7xwaSUsHyMW"
      },
      "source": [
        "# Data preprocessing\n",
        "\n",
        "Train data available at: https://drive.google.com/file/d/1AswiYpd_CIab6swI-XA88H_IBj0Dyd3G\n",
        "\n",
        "Test data available at: https://drive.google.com/file/d/1AsOV43Wc_ZR_1yMbesvq0uNAlUrqK7_Y\n",
        "\n",
        "## Dimension\n",
        "(No. files x width x height x channels)\n",
        "\n",
        "Size of train data: 199 987 x 180 x 60 x 3\n",
        "\n",
        "Size of test data: 49 998 x 180 x 60 x 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9fO-fphHsVL",
        "outputId": "ebecea7a-26de-4e27-bc46-bfdd7c3973cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1AswiYpd_CIab6swI-XA88H_IBj0Dyd3G\n",
            "To: /content/captcha_train.tar.gz\n",
            "100% 1.92G/1.92G [00:16<00:00, 115MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1AsOV43Wc_ZR_1yMbesvq0uNAlUrqK7_Y\n",
            "To: /content/captcha_test.tar.gz\n",
            "100% 480M/480M [00:09<00:00, 51.4MB/s]\n",
            "mkdir: cannot create directory ‘train’: File exists\n",
            "mkdir: cannot create directory ‘test’: File exists\n",
            "train files: 199987\n",
            "test files: 49998\n"
          ]
        }
      ],
      "source": [
        "# download files from google drive\n",
        "\n",
        "# load train data\n",
        "!gdown --id 1AswiYpd_CIab6swI-XA88H_IBj0Dyd3G\n",
        "# load test data\n",
        "!gdown --id 1AsOV43Wc_ZR_1yMbesvq0uNAlUrqK7_Y\n",
        "\n",
        "# create folders to unzip data\n",
        "! mkdir 'train'\n",
        "! mkdir 'test'\n",
        "\n",
        "# unzip data\n",
        "Archive('captcha_train.tar.gz').extractall('train')\n",
        "Archive('captcha_test.tar.gz').extractall('test')\n",
        "\n",
        "# check number of files\n",
        "train_labels = os.listdir('train/train')\n",
        "print('train files:', len(train_labels))\n",
        "\n",
        "test_labels = os.listdir('test/test')\n",
        "print('test files:', len(test_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUYaN93zIztq"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BC_GzmDBI15g"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from pathlib import Path\n",
        "from collections import Counter\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "zafkI_I2I7GP",
        "outputId": "2eef828b-83e4-4aa5-eda1-3075bb28fc24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of train images found:  199987\n",
            "Number of test images found:  49998\n",
            "Number of train labels found:  199987\n",
            "Number of test labels found:  49998\n",
            "Number of unique train characters:  62\n",
            "Number of unique test characters:  62\n",
            "Characters present in train:  {'i', 'V', '6', 'I', 'T', 't', 'B', 'q', 's', '8', 'u', 'v', 'H', 'N', 'M', 'b', 'F', '1', 'G', 'y', 'r', '5', 'P', 'z', '2', 'E', 'w', 'c', 'K', 'U', 'n', 'a', 'X', 'D', 'f', 'Y', 'L', 'k', 'l', 'J', 'p', 'e', 'W', 'C', 'j', 'd', '9', 'O', 'o', 'Q', 'R', '3', '4', 'Z', 'x', '0', 'h', 'A', 'S', 'g', 'm', '7'}\n",
            "Characters present in test:  {'i', 'V', '6', 'I', 'T', 't', 'B', 'q', 's', '8', 'u', 'v', 'H', 'N', 'b', 'M', 'F', '1', 'G', 'y', 'r', '5', 'P', 'z', '2', 'E', 'w', 'c', 'K', 'U', 'n', 'a', 'X', 'D', 'k', 'Y', 'L', 'f', 'l', 'J', 'p', 'W', 'e', 'C', 'j', 'd', '9', 'O', 'Q', 'R', 'o', '3', '4', 'Z', 'x', '0', 'S', 'A', 'h', 'g', 'm', '7'}\n"
          ]
        }
      ],
      "source": [
        "# Path to the data directory\n",
        "data_dir_train = Path(\"./train/train\")\n",
        "data_dir_test = Path(\"./test/test\")\n",
        "\n",
        "# Get list of all the images\n",
        "images_train = sorted(list(map(str, list(data_dir_train.glob(\"*.png\")))))\n",
        "images_test = sorted(list(map(str, list(data_dir_test.glob(\"*.png\")))))\n",
        "\n",
        "labels_train = [img.split(os.path.sep)[-1].split(\".png\")[0] for img in images_train]\n",
        "labels_test = [img.split(os.path.sep)[-1].split(\".png\")[0] for img in images_test]\n",
        "\n",
        "characters_train = set(char for label in labels_train for char in label)\n",
        "characters_test = set(char for label in labels_test for char in label)\n",
        "\n",
        "print(\"Number of train images found: \", len(images_train))\n",
        "print(\"Number of test images found: \", len(images_test))\n",
        "\n",
        "print(\"Number of train labels found: \", len(labels_train))\n",
        "print(\"Number of test labels found: \", len(labels_test))\n",
        "\n",
        "print(\"Number of unique train characters: \", len(characters_train))\n",
        "print(\"Number of unique test characters: \", len(characters_test))\n",
        "\n",
        "print(\"Characters present in train: \", characters_train)\n",
        "print(\"Characters present in test: \", characters_test)\n",
        "\n",
        "# Batch size for training and validation\n",
        "batch_size = 128\n",
        "\n",
        "# Desired image dimensions\n",
        "img_width = 180\n",
        "img_height = 60\n",
        "\n",
        "# Factor by which the image is going to be downsampled\n",
        "# by the convolutional blocks. We will be using two\n",
        "# convolution blocks and each block will have\n",
        "# a pooling layer which downsample the features by a factor of 2.\n",
        "# Hence total downsampling factor would be 4.\n",
        "downsample_factor = 4\n",
        "\n",
        "# Maximum length of any captcha in the dataset\n",
        "max_length_train = max([len(label) for label in labels_train])\n",
        "max_length_test = max([len(label) for label in labels_test])\n",
        "max_length = max([max_length_train,max_length_test])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95dUE-hKLiFf"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Hyo9t2izLbvU"
      },
      "outputs": [],
      "source": [
        "# Mapping characters to integers\n",
        "char_to_num_train = layers.StringLookup(\n",
        "    vocabulary=list(characters_train), mask_token=None)\n",
        "char_to_num_test = layers.StringLookup(\n",
        "    vocabulary=list(characters_test), mask_token=None)\n",
        "\n",
        "\n",
        "# Mapping integers back to original characters\n",
        "num_to_char_train = layers.StringLookup(\n",
        "    vocabulary=char_to_num_train.get_vocabulary(), mask_token=None, invert=True)\n",
        "num_to_char_test = layers.StringLookup(\n",
        "    vocabulary=char_to_num_test.get_vocabulary(), mask_token=None, invert=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rbT-A_cXL5rP"
      },
      "outputs": [],
      "source": [
        "x_train, y_train = images_train, labels_train\n",
        "x_valid, y_valid = images_test, labels_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "aEr5IqaNMTH3"
      },
      "outputs": [],
      "source": [
        "def encode_single_sample(img_path, label):\n",
        "    # 1. Read image\n",
        "    img = tf.io.read_file(img_path)\n",
        "    # 2. Decode and convert to grayscale\n",
        "    img = tf.io.decode_png(img, channels=1)\n",
        "    # 3. Convert to float32 in [0, 1] range\n",
        "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "    # 4. Resize to the desired size\n",
        "    img = tf.image.resize(img, [img_height, img_width])\n",
        "    # 5. Transpose the image because we want the time\n",
        "    # dimension to correspond to the width of the image.\n",
        "    img = tf.transpose(img, perm=[1, 0, 2])\n",
        "    # 6. Map the characters in label to numbers\n",
        "    label = char_to_num_train(tf.strings.unicode_split(label, input_encoding=\"UTF-8\"))\n",
        "    # 7. Return a dict as our model is expecting two inputs\n",
        "    return {\"image\": img, \"label\": label}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVNx8tEEMiI3"
      },
      "source": [
        "## Create Dataset objects"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "__HpnGzZMmCT"
      },
      "outputs": [],
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "train_dataset = (\n",
        "    train_dataset.map(\n",
        "        encode_single_sample, num_parallel_calls=tf.data.AUTOTUNE\n",
        "    )\n",
        "    .batch(batch_size)\n",
        "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        ")\n",
        "\n",
        "validation_dataset = tf.data.Dataset.from_tensor_slices((x_valid, y_valid))\n",
        "validation_dataset = (\n",
        "    validation_dataset.map(\n",
        "        encode_single_sample, num_parallel_calls=tf.data.AUTOTUNE\n",
        "    )\n",
        "    .batch(batch_size)\n",
        "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vOLPEHmNRwI"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "8km3ttRxNRbB",
        "outputId": "7d5c9a4c-4784-453b-e0fa-92bef017c723"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"ocr_model_v1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " image (InputLayer)             [(None, 180, 60, 1)  0           []                               \n",
            "                                ]                                                                 \n",
            "                                                                                                  \n",
            " Conv1 (Conv2D)                 (None, 180, 60, 32)  320         ['image[0][0]']                  \n",
            "                                                                                                  \n",
            " pool1 (MaxPooling2D)           (None, 90, 30, 32)   0           ['Conv1[0][0]']                  \n",
            "                                                                                                  \n",
            " Conv2 (Conv2D)                 (None, 90, 30, 64)   18496       ['pool1[0][0]']                  \n",
            "                                                                                                  \n",
            " pool2 (MaxPooling2D)           (None, 45, 15, 64)   0           ['Conv2[0][0]']                  \n",
            "                                                                                                  \n",
            " reshape (Reshape)              (None, 45, 960)      0           ['pool2[0][0]']                  \n",
            "                                                                                                  \n",
            " dense1 (Dense)                 (None, 45, 64)       61504       ['reshape[0][0]']                \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 45, 64)       0           ['dense1[0][0]']                 \n",
            "                                                                                                  \n",
            " bidirectional (Bidirectional)  (None, 45, 256)      197632      ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " bidirectional_1 (Bidirectional  (None, 45, 128)     164352      ['bidirectional[0][0]']          \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " label (InputLayer)             [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " dense2 (Dense)                 (None, 45, 64)       8256        ['bidirectional_1[0][0]']        \n",
            "                                                                                                  \n",
            " ctc_loss (CTCLayer)            (None, 45, 64)       0           ['label[0][0]',                  \n",
            "                                                                  'dense2[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 450,560\n",
            "Trainable params: 450,560\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "class CTCLayer(layers.Layer):\n",
        "    def __init__(self, name=None):\n",
        "        super().__init__(name=name)\n",
        "        self.loss_fn = keras.backend.ctc_batch_cost\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "        # Compute the training-time loss value and add it\n",
        "        # to the layer using `self.add_loss()`.\n",
        "        batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
        "        input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
        "        label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
        "\n",
        "        input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
        "        label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
        "\n",
        "        loss = self.loss_fn(y_true, y_pred, input_length, label_length)\n",
        "        self.add_loss(loss)\n",
        "\n",
        "        # At test time, just return the computed predictions\n",
        "        return y_pred\n",
        "\n",
        "\n",
        "def build_model():\n",
        "    # Inputs to the model\n",
        "    input_img = layers.Input(\n",
        "        shape=(img_width, img_height, 1), name=\"image\", dtype=\"float32\"\n",
        "    )\n",
        "    labels = layers.Input(name=\"label\", shape=(None,), dtype=\"float32\")\n",
        "\n",
        "    # First conv block\n",
        "    x = layers.Conv2D(\n",
        "        32,\n",
        "        (3, 3),\n",
        "        activation=\"relu\",\n",
        "        kernel_initializer=\"he_normal\",\n",
        "        padding=\"same\",\n",
        "        name=\"Conv1\",\n",
        "    )(input_img)\n",
        "    x = layers.MaxPooling2D((2, 2), name=\"pool1\")(x)\n",
        "\n",
        "    # Second conv block\n",
        "    x = layers.Conv2D(\n",
        "        64,\n",
        "        (3, 3),\n",
        "        activation=\"relu\",\n",
        "        kernel_initializer=\"he_normal\",\n",
        "        padding=\"same\",\n",
        "        name=\"Conv2\",\n",
        "    )(x)\n",
        "    x = layers.MaxPooling2D((2, 2), name=\"pool2\")(x)\n",
        "\n",
        "    # We have used two max pool with pool size and strides 2.\n",
        "    # Hence, downsampled feature maps are 4x smaller. The number of\n",
        "    # filters in the last layer is 64. Reshape accordingly before\n",
        "    # passing the output to the RNN part of the model\n",
        "    new_shape = ((img_width // 4), (img_height // 4) * 64)\n",
        "    x = layers.Reshape(target_shape=new_shape, name=\"reshape\")(x)\n",
        "    x = layers.Dense(64, activation=\"relu\", name=\"dense1\")(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "\n",
        "    # RNNs\n",
        "    x = layers.Bidirectional(layers.LSTM(128, return_sequences=True, dropout=0.25))(x)\n",
        "    x = layers.Bidirectional(layers.LSTM(64, return_sequences=True, dropout=0.25))(x)\n",
        "\n",
        "    # Output layer\n",
        "    x = layers.Dense(\n",
        "        len(char_to_num_train.get_vocabulary()) + 1, activation=\"softmax\", name=\"dense2\"\n",
        "    )(x)\n",
        "\n",
        "    # Add CTC layer for calculating CTC loss at each step\n",
        "    output = CTCLayer(name=\"ctc_loss\")(labels, x)\n",
        "\n",
        "    # Define the model\n",
        "    model = keras.models.Model(\n",
        "        inputs=[input_img, labels], outputs=output, name=\"ocr_model_v1\"\n",
        "    )\n",
        "    # Optimizer\n",
        "    opt = keras.optimizers.Adam()\n",
        "    # Compile the model and return\n",
        "    model.compile(optimizer=opt)\n",
        "    return model\n",
        "\n",
        "\n",
        "# Get the model\n",
        "model = build_model()\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQgX9LMENlD1"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbrrTmTQNkfe",
        "outputId": "836d74f6-03d0-4a12-b4f6-3bbc769dadab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200/200 [==============================] - 3853s 19s/step - loss: 28.7036 - val_loss: 26.7982\n"
          ]
        }
      ],
      "source": [
        "epochs = 100\n",
        "early_stopping_patience = 10\n",
        "# Add early stopping\n",
        "early_stopping = keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_loss\", patience=early_stopping_patience, restore_best_weights=True\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=validation_dataset,\n",
        "    epochs=epochs,\n",
        "    callbacks=[early_stopping],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8woD83IR3Ua"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BECidg6pR1ws"
      },
      "outputs": [],
      "source": [
        "# Get the prediction model by extracting layers till the output layer\n",
        "prediction_model = keras.models.Model(\n",
        "    model.get_layer(name=\"image\").input, model.get_layer(name=\"dense2\").output\n",
        ")\n",
        "prediction_model.summary()\n",
        "\n",
        "# A utility function to decode the output of the network\n",
        "def decode_batch_predictions(pred):\n",
        "    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n",
        "    # Use greedy search. For complex tasks, you can use beam search\n",
        "    results = keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)[0][0][\n",
        "        :, :max_length\n",
        "    ]\n",
        "    # Iterate over the results and get back the text\n",
        "    output_text = []\n",
        "    for res in results:\n",
        "        res = tf.strings.reduce_join(num_to_char_train(res)).numpy().decode(\"utf-8\")\n",
        "        output_text.append(res)\n",
        "    return output_text\n",
        "\n",
        "\n",
        "#  Let's check results on some validation samples\n",
        "for batch in validation_dataset.take(1):\n",
        "    batch_images = batch[\"image\"]\n",
        "    batch_labels = batch[\"label\"]\n",
        "\n",
        "    preds = prediction_model.predict(batch_images)\n",
        "    pred_texts = decode_batch_predictions(preds)\n",
        "\n",
        "    orig_texts = []\n",
        "    for label in batch_labels:\n",
        "        label = tf.strings.reduce_join(num_to_char_train(label)).numpy().decode(\"utf-8\")\n",
        "        orig_texts.append(label)\n",
        "\n",
        "    _, ax = plt.subplots(4, 4, figsize=(15, 5))\n",
        "    for i in range(len(pred_texts)):\n",
        "        img = (batch_images[i, :, :, 0] * 255).numpy().astype(np.uint8)\n",
        "        img = img.T\n",
        "        title = f\"Prediction: {pred_texts[i]}\"\n",
        "        ax[i // 4, i % 4].imshow(img, cmap=\"gray\")\n",
        "        ax[i // 4, i % 4].set_title(title)\n",
        "        ax[i // 4, i % 4].axis(\"off\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "captcha_test_OCR.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyObIjOgPpMTxjb1kSQe2zhX",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}